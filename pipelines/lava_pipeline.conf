# Step 1: retrieve data
input {
    http {
        host => "0.0.0.0"
        port => "9090"
        type => "lava"
    }
}

# Step 2: apply filters and do some magic
filter {

    # Avoid parsing empty stuff
    if [message] =~ /^\s*$/ {
        drop { }
    }

    # Converts input into json
    json {
        source => "message"
    }

    # If input is coming from http, parse GET params
    if [headers] != "" {
        kv {
            include_keys => ["lab_name"]
            field_split => "&?"
            source => "[headers][request_path]"
        }
    }

    # Stash original document data
    ruby {
        init => "require 'yaml';"
        code => " # event.get('log') returns a list of dictionaries, which was messing up parsing it to json
                 definition = {'definition' => YAML.load(event.get('definition'))}
                 event.set('[@metadata][definition]', definition);
                 log ={'log' => YAML.load(event.get('log'))}
                 event.set('[@metadata][log]', log); 

                 # Same as above
                 results = {'results' => YAML.load(event.get('results')['lava'])}
                 event.set('[@metadata][results]', results);"
    }

    mutate {
        # Remove unwanted fields in testjob
        remove_field => ["definition", "log", "results", "message", "host", "@version", "health_string", 
                         "state_string", "state", "health"]

        # Remove fields added by http input plugin
        remove_field => ["headers", "token"]
    } 

    # Set definition as field just so we can use it to get json out of it
    mutate {
        add_field => {
            "definition" => "%{[@metadata][definition]}"
        }
    }

    # Parse field as json
    json {
        source => "definition"
    }

    mutate {
        add_field => {
            "results" => "%{[@metadata][results]}"
        }
    }

   mutate {
        add_field => {
            "log" => "%{[@metadata][log]}"
        }
    }

   

    # Parse field as json
    json {
        source => "results"
    }
    json{
       source => "log"
    }
    
    # Remove the generic type field (used only to determine the index type)
    mutate { add_field => { "[@metadata][index_type]" => "%{type}" } }
    mutate { remove_field => ["type"] }
}

# Step 3: submit it to ES
output {
    elasticsearch {
        hosts => ["127.0.0.1:9200"]
        index => "%{[@metadata][index_type]}-%{[actual_device_id]}-%{+yyyy.MM.dd}"
    }
    # Debugging purposes
    file {
        path => "/tmp/%{[@metadata][index_type]}-%{[actual_device_id]}-%{+yyyy.MM.dd}"
        write_behavior => "overwrite"
    }
}
