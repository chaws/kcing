# Step 1: retrieve data
input {
    stdin {}
}

# Step 2: apply filters and do some magic
filter {

    # Converts input into json
    json {
        source => "message"
    }

    # Consider incoming object as testjob 
    mutate {
        add_field => {
            "type" => "testjob"
        }
    }

    # Stash original document data
    ruby {
        init => "require 'yaml'; require 'json'"
        code => "event.set('[@metadata][definition]', YAML.load(event.get('definition')));

                 # event.get('log') returns a list of dictionaries, which was messing up parsing it to json
                 logs = {'logs' => YAML.load(event.get('log'))}
                 event.set('[@metadata][logs]', logs); 

                 # Same as above
                 results = {'results' => YAML.load(event.get('results')['lava'])}
                 event.set('[@metadata][results]', results);"
    }

    # Remove unwanted fields in testjob
    mutate {
        remove_field => ["definition", "log", "results", "message", "host", "@version", "@timestamp"]
    } 

    # Create copies of simple event objects
    clone {

        # Add common testjob_id field
        add_field => {
          "testjob_id" => "%{id}"
        }

        # Remove testjob fields
        remove_field => ["id", "description", "version", "status_string",
                         "start_time", "boot_log_html", "failure_comment",
                         "metadata", "actual_device_id", "@version", "@timestamp",
                         "host", "submit_time", "end_time", "status", "submitter_username",
                         "priority", "lab_name"] 

        # Define types for new clones
        clones => ["definition", "result", "log"]
    }

    # Build testjob document
    if [type] == 'testjob' {

        # Set testjob id in metadata
        mutate {
            add_field => {
                "[@metadata][id]" => "%{id}"
            }
            remove_field => ["id"]
        }
    }

    # Build definition document
    if [type] == 'definition' {

        # Set definition as field just so we can use it to get json out of it
        mutate {
            add_field => {
                "definition" => "%{[@metadata][definition]}"
            }
        }

        # Parse field as json
        json {
            source => "definition"
        }

        # Remove original string field
        mutate {
            remove_field => ["definition"]
        }
    }

    # Build logs documents
    if [type] == 'log' {
        mutate {
            add_field => {
                "logs" => "%{[@metadata][logs]}"
            }
        }

        # Parse field as json
        json {
            source => "logs"
        }

        split {
            field => "logs"
            remove_field => ["@timestamp", "@version"]
        }

        # Bring nested field 'results' one level up (couldn't find a better way to do this :/)
        mutate {
            add_field => {
                "lvl" => "%{[logs][lvl]}"
                "dt" => "%{[logs][dt]}"
                "msg" => "%{[logs][msg]}"
            }
    
            remove_field => ["logs"]
        }

        # During the conversion, 'msg' got parsed to string, so just parse it back to json
        if [lvl] == 'results' {
            json {
                source => "msg"
                target => "msg"
            }
        }
    }

    # Build results documents
    if [type] == 'result' {
        mutate {
            add_field => {
                "results" => "%{[@metadata][results]}"
            }
        }

        # Parse field as json
        json {
            source => "results"
        }

        split {
            field => "results"
            remove_field => ["@timestamp", "@version"]
        }

        # Bring nested field 'results' one level up (couldn't find a better way to do this :/)
        mutate {
            add_field => {
                "url" => "%{[results][url]}"
                "result" => "%{[results][result]}"
                "unit" => "%{[results][unit]}"
                "metadata" => "%{[results][metadata]}"
                "name" => "%{[results][name]}"
                "measurement" => "%{[results][measurement]}"
                "log_start_line" => "%{[results][log_start_line]}"
                "log_end_line" => "%{[results][log_end_line]}"
                "suite" => "%{[results][suite]}"
                "level" => "%{[results][level]}"
                "logged" => "%{[results][logged]}"
                "id" => "%{[results][id]}"
            }
    
            remove_field => ["results"]
        }

        # During the conversion, 'metadata' got parsed to string, so just parse it back to json
        json {
            source => "metadata"
            target => "metadata"
        }
    }

    # Remove the generic type field (used only to determine the index type)
    mutate { add_field => { "[@metadata][index_type]" => "%{type}" } }
    mutate { remove_field => ["type"] }
}

# Step 3: submit it to ES
output {
    file {
        path => "/tmp/%{[@metadata][index_type]}"
    }
}
